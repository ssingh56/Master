{"cells":[{"cell_type":"code","source":["from pyspark.ml import feature\nfrom pyspark.ml import clustering\nfrom pyspark.ml import Pipeline\nfrom pyspark.sql import functions as fn\nimport numpy as np\nfrom pyspark.sql import SparkSession\nfrom pyspark.ml import feature, regression, evaluation, Pipeline\nfrom pyspark.sql import functions as fn, Row\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport pandas as pd\nfrom pyspark.sql import functions as sf\nfrom pyspark.ml.feature import CountVectorizer\nfrom pyspark.ml.feature import IDF\nfrom pyspark.ml.feature import RegexTokenizer\nimport requests\nfrom pyspark.ml.feature import StopWordsRemover\nfrom pyspark.sql.functions import concat, col, lit, lower\nfrom pyspark.sql.functions import isnan, when, count, col, isnull\nfrom pyspark.sql.functions import concat_ws\nfrom  pyspark.sql.functions import abs\n# seting master(\"local[*]\") enables multicore processing on all available logical cores on your machine\nspark = SparkSession.builder.master(\"local[*]\").getOrCreate()\nsc = spark.sparkContext"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":1},{"cell_type":"code","source":["# Do not delete or change this cell\n\nimport os\n\n# Define a function to determine if we are running on data bricks\n# Return true if running in the data bricks environment, false otherwise\ndef is_databricks():\n    # get the databricks runtime version\n    db_env = os.getenv(\"DATABRICKS_RUNTIME_VERSION\")\n    \n    # if running on data bricks\n    if db_env != None:\n        return True\n    else:\n        return False\n\n# Define a function to read the data file.  The full path data file name is constructed\n# by checking runtime environment variables to determine if the runtime environment is \n# databricks, or a student's personal computer.  The full path file name is then\n# constructed based on the runtime env.\n# \n# Params\n#   data_file_name: The base name of the data file to load\n# \n# Returns the full path file name based on the runtime env\n#\ndef get_training_filename(data_file_name):    \n    # if running on data bricks\n    if is_databricks():\n        # build the full path file name assuming data brick env\n        full_path_name = \"/FileStore/tables/%s\" % data_file_name\n    # else the data is assumed to be in the same dir as this notebook\n    else:\n        # Assume the student is running on their own computer and load the data\n        # file from the same dir as this notebook\n        full_path_name = data_file_name\n    \n    # return the full path file name to the caller\n    return full_path_name"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":2},{"cell_type":"code","source":["airlines_df = spark.read.csv(get_training_filename('airlines.csv'), header=True, inferSchema=True)\nairports_df = spark.read.csv(get_training_filename('airports.csv'), header=True, inferSchema=True)\nflights_df = spark.read.csv(get_training_filename('flights.csv'), header=True, inferSchema=True)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":3},{"cell_type":"code","source":["shape = ((flights_df.count(), len(flights_df.columns)))\nprint('The shape of flights_df:', shape)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">The shape of flights_df: (5819079, 31)\n</div>"]}}],"execution_count":4},{"cell_type":"code","source":["flights_df.select([count(when(isnull(c), c)).alias(c) for c in flights_df.columns]).show()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+----+-----+---+-----------+-------+-------------+-----------+--------------+-------------------+-------------------+--------------+---------------+--------+----------+--------------+------------+--------+--------+---------+-------+-----------------+------------+-------------+--------+---------+-------------------+----------------+--------------+-------------+-------------------+-------------+\nYEAR|MONTH|DAY|DAY_OF_WEEK|AIRLINE|FLIGHT_NUMBER|TAIL_NUMBER|ORIGIN_AIRPORT|DESTINATION_AIRPORT|SCHEDULED_DEPARTURE|DEPARTURE_TIME|DEPARTURE_DELAY|TAXI_OUT|WHEELS_OFF|SCHEDULED_TIME|ELAPSED_TIME|AIR_TIME|DISTANCE|WHEELS_ON|TAXI_IN|SCHEDULED_ARRIVAL|ARRIVAL_TIME|ARRIVAL_DELAY|DIVERTED|CANCELLED|CANCELLATION_REASON|AIR_SYSTEM_DELAY|SECURITY_DELAY|AIRLINE_DELAY|LATE_AIRCRAFT_DELAY|WEATHER_DELAY|\n+----+-----+---+-----------+-------+-------------+-----------+--------------+-------------------+-------------------+--------------+---------------+--------+----------+--------------+------------+--------+--------+---------+-------+-----------------+------------+-------------+--------+---------+-------------------+----------------+--------------+-------------+-------------------+-------------+\n   0|    0|  0|          0|      0|            0|      14721|             0|                  0|                  0|         86153|          86153|   89047|     89047|             6|      105071|  105071|       0|    92513|  92513|                0|       92513|       105071|       0|        0|            5729195|         4755640|       4755640|      4755640|            4755640|      4755640|\n+----+-----+---+-----------+-------+-------------+-----------+--------------+-------------------+-------------------+--------------+---------------+--------+----------+--------------+------------+--------+--------+---------+-------+-----------------+------------+-------------+--------+---------+-------------------+----------------+--------------+-------------+-------------------+-------------+\n\n</div>"]}}],"execution_count":5},{"cell_type":"code","source":["flights_df = flights_df.select('MONTH', 'DAY', 'DAY_OF_WEEK', 'AIRLINE', 'ORIGIN_AIRPORT', 'DESTINATION_AIRPORT', 'SCHEDULED_DEPARTURE', 'DEPARTURE_DELAY', 'DISTANCE', 'SCHEDULED_ARRIVAL', 'ARRIVAL_DELAY', 'CANCELLED')\n\nflights_df = flights_df.filter((fn.col('CANCELLED')==0))\n\nflights_df = flights_df.withColumn(\"Flight_Delayed\", fn.when(fn.col(\"DEPARTURE_DELAY\")<10, 0).otherwise(1))\n\nfrom pyspark.ml.feature import Bucketizer\nbucketizer = Bucketizer(splits=[ 0, 100, 1000, float('Inf') ],inputCol=\"DISTANCE\", outputCol=\"Distance_Bucket\")\nflights_df = bucketizer.setHandleInvalid(\"keep\").transform(flights_df)\n\nfrom pyspark.sql.functions import udf\nfrom pyspark.sql.types import *\n\nt = {0.0:\"Short\", 1.0: \"Medium\", 2.0:\"Long\"}\nudf_foo = udf(lambda x: t[x], StringType())\nflights_df = flights_df.withColumn(\"Flight_Distance\", udf_foo(\"Distance_Bucket\"))\n\nfrom pyspark.ml.feature import StringIndexer\n\nindexer = StringIndexer(inputCol=\"AIRLINE\", outputCol=\"Airline_Numeric\").fit(flights_df)\nflights_df = indexer.transform(flights_df)\n\nfrom pyspark.ml.feature import OneHotEncoder\nencoder = OneHotEncoder(inputCol=\"Airline_Numeric\", outputCol=\"Airline_OHE\")\nflights_df= encoder.transform(flights_df)\n\nindexer = StringIndexer(inputCol=\"ORIGIN_AIRPORT\", outputCol=\"OA_Numeric\").fit(flights_df)\nflights_df = indexer.transform(flights_df)\n\nencoder = OneHotEncoder(inputCol=\"OA_Numeric\", outputCol=\"Origin_Airport_OHE\")\nflights_df= encoder.transform(flights_df)\n\nindexer = StringIndexer(inputCol=\"DESTINATION_AIRPORT\", outputCol=\"DA_Numeric\").fit(flights_df)\nflights_df = indexer.transform(flights_df)\n\nencoder = OneHotEncoder(inputCol=\"DA_Numeric\", outputCol=\"Destination_Airport_OHE\")\nflights_df= encoder.transform(flights_df)\n\nflights_df = flights_df.drop('ARRIVAL_DELAY')\n\n\n"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":6},{"cell_type":"code","source":["from pyspark.sql import functions as fn\nflights_df.groupBy('CANCELLED').agg(fn.count('*')).show()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+---------+--------+\nCANCELLED|count(1)|\n+---------+--------+\n        1|   89884|\n        0| 5729195|\n+---------+--------+\n\n</div>"]}}],"execution_count":7},{"cell_type":"code","source":["flights_df.select(\"DISTANCE\").rdd.max()[0]"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[26]: 4983</div>"]}}],"execution_count":8},{"cell_type":"code","source":["flights_df.select(\"DISTANCE\").rdd.min()[0]"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[27]: 31</div>"]}}],"execution_count":9},{"cell_type":"code","source":["from pyspark.sql import functions as fn\nflights_df.groupBy('Airline_Numeric').agg(fn.count('*')).show()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+---------------+--------+\nAirline_Numeric|count(1)|\n+---------------+--------+\n            8.0|  194648|\n            0.0| 1245812|\n            7.0|  262772|\n            1.0|  872057|\n            4.0|  556746|\n           11.0|   90248|\n            3.0|  578393|\n            2.0|  715065|\n           10.0|  115375|\n           13.0|   61369|\n            6.0|  279607|\n            5.0|  509150|\n            9.0|  171852|\n           12.0|   76101|\n+---------------+--------+\n\n</div>"]}}],"execution_count":10},{"cell_type":"code","source":["flights_df.select('Airline_OHE').take(5)\n"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[75]: [Row(Airline_OHE=SparseVector(13, {9: 1.0})),\n Row(Airline_OHE=SparseVector(13, {2: 1.0})),\n Row(Airline_OHE=SparseVector(13, {8: 1.0})),\n Row(Airline_OHE=SparseVector(13, {2: 1.0})),\n Row(Airline_OHE=SparseVector(13, {9: 1.0}))]</div>"]}}],"execution_count":11},{"cell_type":"code","source":["flights_df.limit(10).toPandas()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>MONTH</th>\n      <th>DAY</th>\n      <th>DAY_OF_WEEK</th>\n      <th>AIRLINE</th>\n      <th>ORIGIN_AIRPORT</th>\n      <th>DESTINATION_AIRPORT</th>\n      <th>SCHEDULED_DEPARTURE</th>\n      <th>DEPARTURE_DELAY</th>\n      <th>DISTANCE</th>\n      <th>SCHEDULED_ARRIVAL</th>\n      <th>ARRIVAL_DELAY</th>\n      <th>CANCELLED</th>\n      <th>Flight_Delayed</th>\n      <th>Distance_Bucket</th>\n      <th>Flight_Distance</th>\n      <th>Airline_Numeric</th>\n      <th>Airline_OHE</th>\n      <th>OA_Numeric</th>\n      <th>Origin_Airport_OHE</th>\n      <th>DA_Numeric</th>\n      <th>Destination_Airport_OHE</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>1</td>\n      <td>4</td>\n      <td>AS</td>\n      <td>ANC</td>\n      <td>SEA</td>\n      <td>5</td>\n      <td>-11</td>\n      <td>1448</td>\n      <td>430</td>\n      <td>-22</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2.0</td>\n      <td>Long</td>\n      <td>9.0</td>\n      <td>(0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n      <td>65.0</td>\n      <td>(0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n      <td>10.0</td>\n      <td>(0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>1</td>\n      <td>4</td>\n      <td>AA</td>\n      <td>LAX</td>\n      <td>PBI</td>\n      <td>10</td>\n      <td>-8</td>\n      <td>2330</td>\n      <td>750</td>\n      <td>-9</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2.0</td>\n      <td>Long</td>\n      <td>2.0</td>\n      <td>(0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n      <td>4.0</td>\n      <td>(0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n      <td>52.0</td>\n      <td>(0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>1</td>\n      <td>4</td>\n      <td>US</td>\n      <td>SFO</td>\n      <td>CLT</td>\n      <td>20</td>\n      <td>-2</td>\n      <td>2296</td>\n      <td>806</td>\n      <td>5</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2.0</td>\n      <td>Long</td>\n      <td>8.0</td>\n      <td>(0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, ...</td>\n      <td>6.0</td>\n      <td>(0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, ...</td>\n      <td>14.0</td>\n      <td>(0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>1</td>\n      <td>4</td>\n      <td>AA</td>\n      <td>LAX</td>\n      <td>MIA</td>\n      <td>20</td>\n      <td>-5</td>\n      <td>2342</td>\n      <td>805</td>\n      <td>-9</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2.0</td>\n      <td>Long</td>\n      <td>2.0</td>\n      <td>(0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n      <td>4.0</td>\n      <td>(0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n      <td>24.0</td>\n      <td>(0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1</td>\n      <td>1</td>\n      <td>4</td>\n      <td>AS</td>\n      <td>SEA</td>\n      <td>ANC</td>\n      <td>25</td>\n      <td>-1</td>\n      <td>1448</td>\n      <td>320</td>\n      <td>-21</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2.0</td>\n      <td>Long</td>\n      <td>9.0</td>\n      <td>(0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n      <td>10.0</td>\n      <td>(0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n      <td>66.0</td>\n      <td>(0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>1</td>\n      <td>1</td>\n      <td>4</td>\n      <td>DL</td>\n      <td>SFO</td>\n      <td>MSP</td>\n      <td>25</td>\n      <td>-5</td>\n      <td>1589</td>\n      <td>602</td>\n      <td>8</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2.0</td>\n      <td>Long</td>\n      <td>1.0</td>\n      <td>(0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n      <td>6.0</td>\n      <td>(0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, ...</td>\n      <td>9.0</td>\n      <td>(0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>1</td>\n      <td>1</td>\n      <td>4</td>\n      <td>NK</td>\n      <td>LAS</td>\n      <td>MSP</td>\n      <td>25</td>\n      <td>-6</td>\n      <td>1299</td>\n      <td>526</td>\n      <td>-17</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2.0</td>\n      <td>Long</td>\n      <td>10.0</td>\n      <td>(0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n      <td>8.0</td>\n      <td>(0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, ...</td>\n      <td>9.0</td>\n      <td>(0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>1</td>\n      <td>1</td>\n      <td>4</td>\n      <td>US</td>\n      <td>LAX</td>\n      <td>CLT</td>\n      <td>30</td>\n      <td>14</td>\n      <td>2125</td>\n      <td>803</td>\n      <td>-10</td>\n      <td>0</td>\n      <td>1</td>\n      <td>2.0</td>\n      <td>Long</td>\n      <td>8.0</td>\n      <td>(0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, ...</td>\n      <td>4.0</td>\n      <td>(0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n      <td>14.0</td>\n      <td>(0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>1</td>\n      <td>1</td>\n      <td>4</td>\n      <td>AA</td>\n      <td>SFO</td>\n      <td>DFW</td>\n      <td>30</td>\n      <td>-11</td>\n      <td>1464</td>\n      <td>545</td>\n      <td>-13</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2.0</td>\n      <td>Long</td>\n      <td>2.0</td>\n      <td>(0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n      <td>6.0</td>\n      <td>(0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, ...</td>\n      <td>2.0</td>\n      <td>(0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>1</td>\n      <td>1</td>\n      <td>4</td>\n      <td>DL</td>\n      <td>LAS</td>\n      <td>ATL</td>\n      <td>30</td>\n      <td>3</td>\n      <td>1747</td>\n      <td>711</td>\n      <td>-15</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2.0</td>\n      <td>Long</td>\n      <td>1.0</td>\n      <td>(0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n      <td>8.0</td>\n      <td>(0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, ...</td>\n      <td>0.0</td>\n      <td>(1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"]}}],"execution_count":12},{"cell_type":"code","source":["flights_df.printSchema()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">root\n-- MONTH: integer (nullable = true)\n-- DAY: integer (nullable = true)\n-- DAY_OF_WEEK: integer (nullable = true)\n-- AIRLINE: string (nullable = true)\n-- ORIGIN_AIRPORT: string (nullable = true)\n-- DESTINATION_AIRPORT: string (nullable = true)\n-- SCHEDULED_DEPARTURE: integer (nullable = true)\n-- DEPARTURE_DELAY: integer (nullable = true)\n-- DISTANCE: integer (nullable = true)\n-- SCHEDULED_ARRIVAL: integer (nullable = true)\n-- CANCELLED: integer (nullable = true)\n-- Flight_Delayed: integer (nullable = false)\n-- Distance_Bucket: double (nullable = true)\n-- Flight_Distance: string (nullable = true)\n-- Airline_Numeric: double (nullable = false)\n-- Airline_OHE: vector (nullable = true)\n-- OA_Numeric: double (nullable = false)\n-- Origin_Airport_OHE: vector (nullable = true)\n-- DA_Numeric: double (nullable = false)\n-- Destination_Airport_OHE: vector (nullable = true)\n\n</div>"]}}],"execution_count":13},{"cell_type":"code","source":["training_df, testing_df = flights_df.randomSplit([0.8, 0.2])"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":14},{"cell_type":"code","source":["testing_df.select([count(when(isnull(c), c)).alias(c) for c in training_df.columns]).show()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+-----+---+-----------+-------+--------------+-------------------+-------------------+---------------+--------+-----------------+---------+--------------+---------------+---------------+---------------+-----------+----------+------------------+----------+-----------------------+\nMONTH|DAY|DAY_OF_WEEK|AIRLINE|ORIGIN_AIRPORT|DESTINATION_AIRPORT|SCHEDULED_DEPARTURE|DEPARTURE_DELAY|DISTANCE|SCHEDULED_ARRIVAL|CANCELLED|Flight_Delayed|Distance_Bucket|Flight_Distance|Airline_Numeric|Airline_OHE|OA_Numeric|Origin_Airport_OHE|DA_Numeric|Destination_Airport_OHE|\n+-----+---+-----------+-------+--------------+-------------------+-------------------+---------------+--------+-----------------+---------+--------------+---------------+---------------+---------------+-----------+----------+------------------+----------+-----------------------+\n    0|  0|          0|      0|             0|                  0|                  0|              0|       0|                0|        0|             0|              0|              0|              0|          0|         0|                 0|         0|                      0|\n+-----+---+-----------+-------+--------------+-------------------+-------------------+---------------+--------+-----------------+---------+--------------+---------------+---------------+---------------+-----------+----------+------------------+----------+-----------------------+\n\n</div>"]}}],"execution_count":15},{"cell_type":"code","source":["\ntraining_df.groupBy('Flight_Delayed').agg(fn.count('*')).show()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+--------------+--------+\nFlight_Delayed|count(1)|\n+--------------+--------+\n             1| 1034370|\n             0| 3549173|\n+--------------+--------+\n\n</div>"]}}],"execution_count":16},{"cell_type":"code","source":["from pyspark.ml.feature import VectorAssembler\n\nva = VectorAssembler(\n    inputCols=[\"MONTH\", \"DAY\", \"DAY_OF_WEEK\", \"Airline_OHE\", \"Origin_Airport_OHE\", \"Destination_Airport_OHE\", \"SCHEDULED_DEPARTURE\", \"Distance_Bucket\", \"SCHEDULED_ARRIVAL\", \"CANCELLED\"], outputCol=\"features\")"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":17},{"cell_type":"code","source":["from pyspark.ml.classification import LogisticRegression, RandomForestClassifier\nfrom pyspark.ml import Pipeline\nfrom pyspark.ml.evaluation import BinaryClassificationEvaluator\nfrom pyspark.ml.classification import GBTClassifier\nfrom pyspark.ml.tuning import CrossValidator, ParamGridBuilder\nfrom pyspark.ml.tuning import CrossValidatorModel\nbce = BinaryClassificationEvaluator(labelCol='Flight_Delayed', metricName='areaUnderROC')\nfrom pyspark.ml import evaluation\nlr_evaluator_f1 = evaluation.MulticlassClassificationEvaluator(labelCol=\"Flight_Delayed\", metricName=\"f1\")\nrf_evaluator_f1 = evaluation.MulticlassClassificationEvaluator(labelCol=\"Flight_Delayed\", metricName=\"f1\")"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":18},{"cell_type":"code","source":["lr = LogisticRegression(featuresCol='features', labelCol='Flight_Delayed', regParam=0.1)\nlr_pipeline = Pipeline(stages=[va, lr]).fit(training_df)\n#bce.evaluate(lr_pipeline.transform(testing_df))\nlr_evaluator_f1.evaluate(lr_pipeline.transform(testing_df))"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[11]: 0.6762311713076905</div>"]}}],"execution_count":19},{"cell_type":"code","source":["lr_evaluator_recall = evaluation.MulticlassClassificationEvaluator(labelCol=\"Flight_Delayed\", metricName=\"weightedRecall\")\nlr_evaluator_recall.evaluate(lr_pipeline.transform(testing_df))"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[12]: 0.7746121858993831</div>"]}}],"execution_count":20},{"cell_type":"code","source":["lr_evaluator_precision = evaluation.MulticlassClassificationEvaluator(labelCol=\"Flight_Delayed\", metricName=\"weightedPrecision\")\nlr_evaluator_precision.evaluate(lr_pipeline.transform(testing_df))"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[13]: 0.6000240385438204</div>"]}}],"execution_count":21},{"cell_type":"code","source":["lr_evaluator_accuracy = evaluation.MulticlassClassificationEvaluator(labelCol=\"Flight_Delayed\", metricName=\"accuracy\")\nlr_evaluator_accuracy.evaluate(lr_pipeline.transform(testing_df))"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[14]: 0.7746121858993831</div>"]}}],"execution_count":22},{"cell_type":"code","source":["rf = RandomForestClassifier(featuresCol='features', labelCol='Flight_Delayed', numTrees=3, maxDepth=4, impurity=\"gini\")\nrf_pipeline = Pipeline(stages=[va, rf]).fit(training_df)\n#bce.evaluate(rf_pipeline.transform(testing_df))\nrf_evaluator_f1.evaluate(rf_pipeline.transform(testing_df))"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[15]: 0.6762311713076905</div>"]}}],"execution_count":23},{"cell_type":"code","source":["rf_evaluator_recall = evaluation.MulticlassClassificationEvaluator(labelCol=\"Flight_Delayed\", metricName=\"weightedRecall\")\nrf_evaluator_recall.evaluate(rf_pipeline.transform(testing_df))"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[16]: 0.7746121858993831</div>"]}}],"execution_count":24},{"cell_type":"code","source":["rf_evaluator_Precision = evaluation.MulticlassClassificationEvaluator(labelCol=\"Flight_Delayed\", metricName=\"weightedPrecision\")\nrf_evaluator_Precision.evaluate(rf_pipeline.transform(testing_df))"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[17]: 0.6000240385438204</div>"]}}],"execution_count":25},{"cell_type":"code","source":["rf_evaluator_accuracy = evaluation.MulticlassClassificationEvaluator(labelCol=\"Flight_Delayed\", metricName=\"accuracy\")\nrf_evaluator_accuracy.evaluate(rf_pipeline.transform(testing_df))"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[18]: 0.7746121858993831</div>"]}}],"execution_count":26},{"cell_type":"code","source":["gbt = GBTClassifier(featuresCol='features', labelCol='Flight_Delayed')\ngbt_pipeline = Pipeline(stages=[va, gbt]).fit(training_df)\n#bce.evaluate(gbt_pipeline.transform(testing_df))\nevaluator.evaluate(gbt_pipeline.transform(testing_df))"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\njava.io.IOException: Connection failed\n\tat com.databricks.rpc.Jetty9Client$$anon$1.handleError(Jetty9Client.scala:468)\n\tat com.databricks.rpc.Jetty9Client$$anon$1.onFailure(Jetty9Client.scala:395)\n\tat shaded.v9_4.org.eclipse.jetty.client.ResponseNotifier.notifyFailure(ResponseNotifier.java:177)\n\tat shaded.v9_4.org.eclipse.jetty.client.ResponseNotifier.notifyFailure(ResponseNotifier.java:169)\n\tat shaded.v9_4.org.eclipse.jetty.client.HttpExchange.notifyFailureComplete(HttpExchange.java:268)\n\tat shaded.v9_4.org.eclipse.jetty.client.HttpExchange.abort(HttpExchange.java:240)\n\tat shaded.v9_4.org.eclipse.jetty.client.HttpConversation.abort(HttpConversation.java:149)\n\tat shaded.v9_4.org.eclipse.jetty.client.HttpRequest.abort(HttpRequest.java:768)\n\tat shaded.v9_4.org.eclipse.jetty.client.HttpDestination.abort(HttpDestination.java:453)\n\tat shaded.v9_4.org.eclipse.jetty.client.HttpDestination.failed(HttpDestination.java:234)\n\tat shaded.v9_4.org.eclipse.jetty.client.AbstractConnectionPool$1.failed(AbstractConnectionPool.java:140)\n\tat shaded.v9_4.org.eclipse.jetty.util.Promise$Wrapper.failed(Promise.java:136)\n\tat shaded.v9_4.org.eclipse.jetty.client.HttpClient$1$1.failed(HttpClient.java:612)\n\tat shaded.v9_4.org.eclipse.jetty.client.AbstractConnectorHttpClientTransport.connectFailed(AbstractConnectorHttpClientTransport.java:138)\n\tat shaded.v9_4.org.eclipse.jetty.client.AbstractConnectorHttpClientTransport$ClientSelectorManager.connectionFailed(AbstractConnectorHttpClientTransport.java:188)\n\tat shaded.v9_4.org.eclipse.jetty.io.ManagedSelector$Connect.failed(ManagedSelector.java:822)\n\tat shaded.v9_4.org.eclipse.jetty.io.ManagedSelector.processConnect(ManagedSelector.java:254)\n\tat shaded.v9_4.org.eclipse.jetty.io.ManagedSelector.access$1400(ManagedSelector.java:62)\n\tat shaded.v9_4.org.eclipse.jetty.io.ManagedSelector$SelectorProducer.processSelected(ManagedSelector.java:543)\n\tat shaded.v9_4.org.eclipse.jetty.io.ManagedSelector$SelectorProducer.produce(ManagedSelector.java:401)\n\tat shaded.v9_4.org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produceTask(EatWhatYouKill.java:360)\n\tat shaded.v9_4.org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:184)\n\tat shaded.v9_4.org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:171)\n\tat shaded.v9_4.org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:129)\n\tat shaded.v9_4.org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:367)\n\tat shaded.v9_4.org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:782)\n\tat shaded.v9_4.org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:914)\n\tat java.lang.Thread.run(Thread.java:748)\nCaused by: java.net.ConnectException: Connection refused\n\tat sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)\n\tat sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:714)\n\tat shaded.v9_4.org.eclipse.jetty.io.SelectorManager.doFinishConnect(SelectorManager.java:355)\n\tat shaded.v9_4.org.eclipse.jetty.io.ManagedSelector.processConnect(ManagedSelector.java:232)\n\t... 11 more"]}}],"execution_count":27},{"cell_type":"code","source":["rf_pipe = Pipeline(stages=[rf])"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansi-red-fg\">---------------------------------------------------------------------------</span>\n<span class=\"ansi-red-fg\">NameError</span>                                 Traceback (most recent call last)\n<span class=\"ansi-green-fg\">&lt;command-3202703016655738&gt;</span> in <span class=\"ansi-cyan-fg\">&lt;module&gt;</span>\n<span class=\"ansi-green-fg\">----&gt; 1</span><span class=\"ansi-red-fg\"> </span>rf_pipe <span class=\"ansi-blue-fg\">=</span> Pipeline<span class=\"ansi-blue-fg\">(</span>stages<span class=\"ansi-blue-fg\">=</span><span class=\"ansi-blue-fg\">[</span>rf<span class=\"ansi-blue-fg\">]</span><span class=\"ansi-blue-fg\">)</span>\n\n<span class=\"ansi-red-fg\">NameError</span>: name &#39;Pipeline&#39; is not defined</div>"]}}],"execution_count":28},{"cell_type":"code","source":["paramGrid = ParamGridBuilder()\\\n  .addGrid(rf.maxBins, [25, 28, 31])\\\n  .addGrid(rf.maxDepth, [4, 6, 8])\\\n  .addGrid(rf.numTrees, [10, 20, 30])\\\n  .addGrid(rf.impurity, [\"entropy\", \"gini\"])\\\n  .build()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":29},{"cell_type":"code","source":["cv = CrossValidator()\\\n  .setEstimator(rf_pipe)\\\n  .setEvaluator(evaluator)\\\n  .setEstimatorParamMaps(paramGrid)\\\n  .setNumFolds(3)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":30},{"cell_type":"code","source":["cv_pipeline = Pipeline(stages=[va,cv]).fit(training_df)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\njava.io.IOException: Connection failed\n\tat com.databricks.rpc.Jetty9Client$$anon$1.handleError(Jetty9Client.scala:468)\n\tat com.databricks.rpc.Jetty9Client$$anon$1.onFailure(Jetty9Client.scala:395)\n\tat shaded.v9_4.org.eclipse.jetty.client.ResponseNotifier.notifyFailure(ResponseNotifier.java:177)\n\tat shaded.v9_4.org.eclipse.jetty.client.ResponseNotifier.notifyFailure(ResponseNotifier.java:169)\n\tat shaded.v9_4.org.eclipse.jetty.client.HttpExchange.notifyFailureComplete(HttpExchange.java:268)\n\tat shaded.v9_4.org.eclipse.jetty.client.HttpExchange.abort(HttpExchange.java:240)\n\tat shaded.v9_4.org.eclipse.jetty.client.HttpConversation.abort(HttpConversation.java:149)\n\tat shaded.v9_4.org.eclipse.jetty.client.HttpRequest.abort(HttpRequest.java:768)\n\tat shaded.v9_4.org.eclipse.jetty.client.HttpDestination.abort(HttpDestination.java:453)\n\tat shaded.v9_4.org.eclipse.jetty.client.HttpDestination.failed(HttpDestination.java:234)\n\tat shaded.v9_4.org.eclipse.jetty.client.AbstractConnectionPool$1.failed(AbstractConnectionPool.java:140)\n\tat shaded.v9_4.org.eclipse.jetty.util.Promise$Wrapper.failed(Promise.java:136)\n\tat shaded.v9_4.org.eclipse.jetty.client.HttpClient$1$1.failed(HttpClient.java:612)\n\tat shaded.v9_4.org.eclipse.jetty.client.AbstractConnectorHttpClientTransport.connectFailed(AbstractConnectorHttpClientTransport.java:138)\n\tat shaded.v9_4.org.eclipse.jetty.client.AbstractConnectorHttpClientTransport$ClientSelectorManager.connectionFailed(AbstractConnectorHttpClientTransport.java:188)\n\tat shaded.v9_4.org.eclipse.jetty.io.ManagedSelector$Connect.failed(ManagedSelector.java:822)\n\tat shaded.v9_4.org.eclipse.jetty.io.ManagedSelector.processConnect(ManagedSelector.java:254)\n\tat shaded.v9_4.org.eclipse.jetty.io.ManagedSelector.access$1400(ManagedSelector.java:62)\n\tat shaded.v9_4.org.eclipse.jetty.io.ManagedSelector$SelectorProducer.processSelected(ManagedSelector.java:543)\n\tat shaded.v9_4.org.eclipse.jetty.io.ManagedSelector$SelectorProducer.produce(ManagedSelector.java:401)\n\tat shaded.v9_4.org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produceTask(EatWhatYouKill.java:360)\n\tat shaded.v9_4.org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:184)\n\tat shaded.v9_4.org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:171)\n\tat shaded.v9_4.org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:129)\n\tat shaded.v9_4.org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:367)\n\tat shaded.v9_4.org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:782)\n\tat shaded.v9_4.org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:914)\n\tat java.lang.Thread.run(Thread.java:748)\nCaused by: java.net.ConnectException: Connection refused\n\tat sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)\n\tat sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:714)\n\tat shaded.v9_4.org.eclipse.jetty.io.SelectorManager.doFinishConnect(SelectorManager.java:355)\n\tat shaded.v9_4.org.eclipse.jetty.io.ManagedSelector.processConnect(ManagedSelector.java:232)\n\t... 11 more"]}}],"execution_count":31},{"cell_type":"code","source":["evaluator.evaluate(cv_pipeline.transform(testing_df))"],"metadata":{},"outputs":[],"execution_count":32},{"cell_type":"code","source":["from pyspark.ml import classification\n\nmlp = classification.MultilayerPerceptronClassifier(featuresCol='features', labelCol='Flight_Delayed', layers=[4,5,4,2])\nmlp_pipeline = Pipeline(stages=[va, mlp]).fit(training_df)\nevaluator.evaluate(mlp_pipeline.transform(testing_df))"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansi-red-fg\">---------------------------------------------------------------------------</span>\n<span class=\"ansi-red-fg\">Py4JJavaError</span>                             Traceback (most recent call last)\n<span class=\"ansi-green-fg\">&lt;command-4117519078817409&gt;</span> in <span class=\"ansi-cyan-fg\">&lt;module&gt;</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">      3</span> mlp <span class=\"ansi-blue-fg\">=</span> classification<span class=\"ansi-blue-fg\">.</span>MultilayerPerceptronClassifier<span class=\"ansi-blue-fg\">(</span>featuresCol<span class=\"ansi-blue-fg\">=</span><span class=\"ansi-blue-fg\">&#39;features&#39;</span><span class=\"ansi-blue-fg\">,</span> labelCol<span class=\"ansi-blue-fg\">=</span><span class=\"ansi-blue-fg\">&#39;Flight_Delayed&#39;</span><span class=\"ansi-blue-fg\">,</span> layers<span class=\"ansi-blue-fg\">=</span><span class=\"ansi-blue-fg\">[</span><span class=\"ansi-cyan-fg\">4</span><span class=\"ansi-blue-fg\">,</span><span class=\"ansi-cyan-fg\">5</span><span class=\"ansi-blue-fg\">,</span><span class=\"ansi-cyan-fg\">4</span><span class=\"ansi-blue-fg\">,</span><span class=\"ansi-cyan-fg\">2</span><span class=\"ansi-blue-fg\">]</span><span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">      4</span> mlp_pipeline <span class=\"ansi-blue-fg\">=</span> Pipeline<span class=\"ansi-blue-fg\">(</span>stages<span class=\"ansi-blue-fg\">=</span><span class=\"ansi-blue-fg\">[</span>va<span class=\"ansi-blue-fg\">,</span> mlp<span class=\"ansi-blue-fg\">]</span><span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">.</span>fit<span class=\"ansi-blue-fg\">(</span>training_df<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-fg\">----&gt; 5</span><span class=\"ansi-red-fg\"> </span>evaluator<span class=\"ansi-blue-fg\">.</span>evaluate<span class=\"ansi-blue-fg\">(</span>mlp_pipeline<span class=\"ansi-blue-fg\">.</span>transform<span class=\"ansi-blue-fg\">(</span>testing_df<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">)</span>\n\n<span class=\"ansi-green-fg\">/databricks/spark/python/pyspark/ml/evaluation.py</span> in <span class=\"ansi-cyan-fg\">evaluate</span><span class=\"ansi-blue-fg\">(self, dataset, params)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">     69</span>                 <span class=\"ansi-green-fg\">return</span> self<span class=\"ansi-blue-fg\">.</span>copy<span class=\"ansi-blue-fg\">(</span>params<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">.</span>_evaluate<span class=\"ansi-blue-fg\">(</span>dataset<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">     70</span>             <span class=\"ansi-green-fg\">else</span><span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-fg\">---&gt; 71</span><span class=\"ansi-red-fg\">                 </span><span class=\"ansi-green-fg\">return</span> self<span class=\"ansi-blue-fg\">.</span>_evaluate<span class=\"ansi-blue-fg\">(</span>dataset<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">     72</span>         <span class=\"ansi-green-fg\">else</span><span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">     73</span>             <span class=\"ansi-green-fg\">raise</span> ValueError<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">&#34;Params must be a param map but got %s.&#34;</span> <span class=\"ansi-blue-fg\">%</span> type<span class=\"ansi-blue-fg\">(</span>params<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">)</span>\n\n<span class=\"ansi-green-fg\">/databricks/spark/python/pyspark/ml/evaluation.py</span> in <span class=\"ansi-cyan-fg\">_evaluate</span><span class=\"ansi-blue-fg\">(self, dataset)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">     99</span>         &#34;&#34;&#34;\n<span class=\"ansi-green-intense-fg ansi-bold\">    100</span>         self<span class=\"ansi-blue-fg\">.</span>_transfer_params_to_java<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-fg\">--&gt; 101</span><span class=\"ansi-red-fg\">         </span><span class=\"ansi-green-fg\">return</span> self<span class=\"ansi-blue-fg\">.</span>_java_obj<span class=\"ansi-blue-fg\">.</span>evaluate<span class=\"ansi-blue-fg\">(</span>dataset<span class=\"ansi-blue-fg\">.</span>_jdf<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    102</span> \n<span class=\"ansi-green-intense-fg ansi-bold\">    103</span>     <span class=\"ansi-green-fg\">def</span> isLargerBetter<span class=\"ansi-blue-fg\">(</span>self<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">:</span>\n\n<span class=\"ansi-green-fg\">/databricks/spark/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py</span> in <span class=\"ansi-cyan-fg\">__call__</span><span class=\"ansi-blue-fg\">(self, *args)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">   1255</span>         answer <span class=\"ansi-blue-fg\">=</span> self<span class=\"ansi-blue-fg\">.</span>gateway_client<span class=\"ansi-blue-fg\">.</span>send_command<span class=\"ansi-blue-fg\">(</span>command<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">   1256</span>         return_value = get_return_value(\n<span class=\"ansi-green-fg\">-&gt; 1257</span><span class=\"ansi-red-fg\">             answer, self.gateway_client, self.target_id, self.name)\n</span><span class=\"ansi-green-intense-fg ansi-bold\">   1258</span> \n<span class=\"ansi-green-intense-fg ansi-bold\">   1259</span>         <span class=\"ansi-green-fg\">for</span> temp_arg <span class=\"ansi-green-fg\">in</span> temp_args<span class=\"ansi-blue-fg\">:</span>\n\n<span class=\"ansi-green-fg\">/databricks/spark/python/pyspark/sql/utils.py</span> in <span class=\"ansi-cyan-fg\">deco</span><span class=\"ansi-blue-fg\">(*a, **kw)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">     61</span>     <span class=\"ansi-green-fg\">def</span> deco<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">*</span>a<span class=\"ansi-blue-fg\">,</span> <span class=\"ansi-blue-fg\">**</span>kw<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">     62</span>         <span class=\"ansi-green-fg\">try</span><span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-fg\">---&gt; 63</span><span class=\"ansi-red-fg\">             </span><span class=\"ansi-green-fg\">return</span> f<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">*</span>a<span class=\"ansi-blue-fg\">,</span> <span class=\"ansi-blue-fg\">**</span>kw<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">     64</span>         <span class=\"ansi-green-fg\">except</span> py4j<span class=\"ansi-blue-fg\">.</span>protocol<span class=\"ansi-blue-fg\">.</span>Py4JJavaError <span class=\"ansi-green-fg\">as</span> e<span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">     65</span>             s <span class=\"ansi-blue-fg\">=</span> e<span class=\"ansi-blue-fg\">.</span>java_exception<span class=\"ansi-blue-fg\">.</span>toString<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">)</span>\n\n<span class=\"ansi-green-fg\">/databricks/spark/python/lib/py4j-0.10.7-src.zip/py4j/protocol.py</span> in <span class=\"ansi-cyan-fg\">get_return_value</span><span class=\"ansi-blue-fg\">(answer, gateway_client, target_id, name)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    326</span>                 raise Py4JJavaError(\n<span class=\"ansi-green-intense-fg ansi-bold\">    327</span>                     <span class=\"ansi-blue-fg\">&#34;An error occurred while calling {0}{1}{2}.\\n&#34;</span><span class=\"ansi-blue-fg\">.</span>\n<span class=\"ansi-green-fg\">--&gt; 328</span><span class=\"ansi-red-fg\">                     format(target_id, &#34;.&#34;, name), value)\n</span><span class=\"ansi-green-intense-fg ansi-bold\">    329</span>             <span class=\"ansi-green-fg\">else</span><span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    330</span>                 raise Py4JError(\n\n<span class=\"ansi-red-fg\">Py4JJavaError</span>: An error occurred while calling o1065.evaluate.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 7 in stage 735.0 failed 1 times, most recent failure: Lost task 7.0 in stage 735.0 (TID 3690, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function($anonfun$1: (struct&lt;type:tinyint,size:int,indices:array&lt;int&gt;,values:array&lt;double&gt;&gt;) =&gt; struct&lt;type:tinyint,size:int,indices:array&lt;int&gt;,values:array&lt;double&gt;&gt;)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage2.processNext(Unknown Source)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$13$$anon$1.hasNext(WholeStageCodegenExec.scala:640)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)\n\tat org.apache.spark.util.collection.ExternalSorter.insertAll(ExternalSorter.scala:191)\n\tat org.apache.spark.shuffle.sort.SortShuffleWriter.write(SortShuffleWriter.scala:62)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:55)\n\tat org.apache.spark.scheduler.Task.doRunTask(Task.scala:140)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:113)\n\tat org.apache.spark.executor.Executor$TaskRunner$$anonfun$13.apply(Executor.scala:537)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1541)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:543)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\nCaused by: java.lang.IllegalArgumentException: requirement failed: A &amp; B Dimension mismatch!\n\tat scala.Predef$.require(Predef.scala:224)\n\tat org.apache.spark.ml.ann.BreezeUtil$.dgemm(BreezeUtil.scala:41)\n\tat org.apache.spark.ml.ann.AffineLayerModel.eval(Layer.scala:164)\n\tat org.apache.spark.ml.ann.FeedForwardModel.forward(Layer.scala:508)\n\tat org.apache.spark.ml.ann.FeedForwardModel.predictRaw(Layer.scala:561)\n\tat org.apache.spark.ml.classification.MultilayerPerceptronClassificationModel.predictRaw(MultilayerPerceptronClassifier.scala:323)\n\tat org.apache.spark.ml.classification.MultilayerPerceptronClassificationModel.predictRaw(MultilayerPerceptronClassifier.scala:280)\n\tat org.apache.spark.ml.classification.ProbabilisticClassificationModel$$anonfun$1.apply(ProbabilisticClassifier.scala:119)\n\tat org.apache.spark.ml.classification.ProbabilisticClassificationModel$$anonfun$1.apply(ProbabilisticClassifier.scala:118)\n\t... 19 more\n\nDriver stacktrace:\n\tat org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:2362)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:2350)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:2349)\n\tat scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2349)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:1102)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:1102)\n\tat scala.Option.foreach(Option.scala:257)\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1102)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2582)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2529)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2517)\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:897)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2280)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2302)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2321)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2346)\n\tat org.apache.spark.rdd.RDD$$anonfun$collect$1.apply(RDD.scala:997)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:392)\n\tat org.apache.spark.rdd.RDD.collect(RDD.scala:996)\n\tat org.apache.spark.rdd.PairRDDFunctions$$anonfun$collectAsMap$1.apply(PairRDDFunctions.scala:743)\n\tat org.apache.spark.rdd.PairRDDFunctions$$anonfun$collectAsMap$1.apply(PairRDDFunctions.scala:742)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:392)\n\tat org.apache.spark.rdd.PairRDDFunctions.collectAsMap(PairRDDFunctions.scala:742)\n\tat org.apache.spark.mllib.evaluation.MulticlassMetrics.tpByClass$lzycompute(MulticlassMetrics.scala:48)\n\tat org.apache.spark.mllib.evaluation.MulticlassMetrics.tpByClass(MulticlassMetrics.scala:44)\n\tat org.apache.spark.mllib.evaluation.MulticlassMetrics.accuracy$lzycompute(MulticlassMetrics.scala:168)\n\tat org.apache.spark.mllib.evaluation.MulticlassMetrics.accuracy(MulticlassMetrics.scala:168)\n\tat org.apache.spark.ml.evaluation.MulticlassClassificationEvaluator.evaluate(MulticlassClassificationEvaluator.scala:87)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:380)\n\tat py4j.Gateway.invoke(Gateway.java:295)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:251)\n\tat java.lang.Thread.run(Thread.java:748)\nCaused by: org.apache.spark.SparkException: Failed to execute user defined function($anonfun$1: (struct&lt;type:tinyint,size:int,indices:array&lt;int&gt;,values:array&lt;double&gt;&gt;) =&gt; struct&lt;type:tinyint,size:int,indices:array&lt;int&gt;,values:array&lt;double&gt;&gt;)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage2.processNext(Unknown Source)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$13$$anon$1.hasNext(WholeStageCodegenExec.scala:640)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)\n\tat org.apache.spark.util.collection.ExternalSorter.insertAll(ExternalSorter.scala:191)\n\tat org.apache.spark.shuffle.sort.SortShuffleWriter.write(SortShuffleWriter.scala:62)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:55)\n\tat org.apache.spark.scheduler.Task.doRunTask(Task.scala:140)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:113)\n\tat org.apache.spark.executor.Executor$TaskRunner$$anonfun$13.apply(Executor.scala:537)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1541)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:543)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\t... 1 more\nCaused by: java.lang.IllegalArgumentException: requirement failed: A &amp; B Dimension mismatch!\n\tat scala.Predef$.require(Predef.scala:224)\n\tat org.apache.spark.ml.ann.BreezeUtil$.dgemm(BreezeUtil.scala:41)\n\tat org.apache.spark.ml.ann.AffineLayerModel.eval(Layer.scala:164)\n\tat org.apache.spark.ml.ann.FeedForwardModel.forward(Layer.scala:508)\n\tat org.apache.spark.ml.ann.FeedForwardModel.predictRaw(Layer.scala:561)\n\tat org.apache.spark.ml.classification.MultilayerPerceptronClassificationModel.predictRaw(MultilayerPerceptronClassifier.scala:323)\n\tat org.apache.spark.ml.classification.MultilayerPerceptronClassificationModel.predictRaw(MultilayerPerceptronClassifier.scala:280)\n\tat org.apache.spark.ml.classification.ProbabilisticClassificationModel$$anonfun$1.apply(ProbabilisticClassifier.scala:119)\n\tat org.apache.spark.ml.classification.ProbabilisticClassificationModel$$anonfun$1.apply(ProbabilisticClassifier.scala:118)\n\t... 19 more\n</div>"]}}],"execution_count":33},{"cell_type":"code","source":["from pyspark.ml.classification import LinearSVC\n\nsvm = LinearSVC(featuresCol='features', labelCol='Flight_Delayed', maxIter=10, regParam=0.1)\nsvm_pipeline = Pipeline(stages=[va, svm]).fit(training_df)\nevaluator.evaluate(svm_pipeline.transform(testing_df))\n"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[22]: 0.7754379526967401</div>"]}}],"execution_count":34},{"cell_type":"code","source":["from pyspark.ml import feature\n\npca = PCA(k=2, inputCol=\"features\", outputCol=\"pca_features\")\n model = pca.fit(df)\n model.transform(df).collect()"],"metadata":{},"outputs":[],"execution_count":35},{"cell_type":"code","source":["flights_df_sample = flights_df.sample(True, 0.5, 42)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":36},{"cell_type":"code","source":["shape = ((flights_df_sample.count(), len(flights_df_sample.columns)))\nprint('The shape of flights_df_sample:', shape)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">The shape of flights_df_sample: (2862296, 20)\n</div>"]}}],"execution_count":37},{"cell_type":"code","source":["flights_df_sample.printSchema()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">root\n-- MONTH: integer (nullable = true)\n-- DAY: integer (nullable = true)\n-- DAY_OF_WEEK: integer (nullable = true)\n-- AIRLINE: string (nullable = true)\n-- ORIGIN_AIRPORT: string (nullable = true)\n-- DESTINATION_AIRPORT: string (nullable = true)\n-- SCHEDULED_DEPARTURE: integer (nullable = true)\n-- DEPARTURE_DELAY: integer (nullable = true)\n-- DISTANCE: integer (nullable = true)\n-- SCHEDULED_ARRIVAL: integer (nullable = true)\n-- CANCELLED: integer (nullable = true)\n-- Flight_Delayed: integer (nullable = false)\n-- Distance_Bucket: double (nullable = true)\n-- Flight_Distance: string (nullable = true)\n-- Airline_Numeric: double (nullable = false)\n-- Airline_OHE: vector (nullable = true)\n-- OA_Numeric: double (nullable = false)\n-- Origin_Airport_OHE: vector (nullable = true)\n-- DA_Numeric: double (nullable = false)\n-- Destination_Airport_OHE: vector (nullable = true)\n\n</div>"]}}],"execution_count":38},{"cell_type":"code","source":["flights_df_sample_pandas = flights_df_sample.toPandas()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">/databricks/spark/python/pyspark/sql/dataframe.py:2163: UserWarning: toPandas attempted Arrow optimization because &#39;spark.sql.execution.arrow.enabled&#39; is set to true; however, failed by the reason below:\n  Unsupported type in conversion to Arrow: VectorUDT\nAttempting non-optimization as &#39;spark.sql.execution.arrow.fallback.enabled&#39; is set to true.\n  warnings.warn(msg)\n</div>"]}}],"execution_count":39},{"cell_type":"code","source":["flights_df_sample.groupBy('Flight_Delayed').agg(fn.count('*')).show()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+--------------+--------+\nFlight_Delayed|count(1)|\n+--------------+--------+\n             1|  646606|\n             0| 2215690|\n+--------------+--------+\n\n</div>"]}}],"execution_count":40},{"cell_type":"code","source":["flights_df.groupBy('Flight_Delayed').agg(fn.count('*')).show()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+--------------+--------+\nFlight_Delayed|count(1)|\n+--------------+--------+\n             1| 1292586|\n             0| 4436609|\n+--------------+--------+\n\n</div>"]}}],"execution_count":41},{"cell_type":"code","source":["from pyspark.ml.stat import Correlation\n\n# convert to vector column first\nvector_col = \"corr_features\"\nassembler = VectorAssembler(inputCols=[\"MONTH\", \"DAY\", \"DAY_OF_WEEK\", \"Airline_OHE\", \"Origin_Airport_OHE\", \"Destination_Airport_OHE\", \"SCHEDULED_DEPARTURE\", \"Distance_Bucket\", \"SCHEDULED_ARRIVAL\", \"CANCELLED\", \"Flight_Delayed\"], outputCol=vector_col)\ndf_vector = assembler.transform(flights_df).select(vector_col)\n\n# get correlation matrix\nmatrix = Correlation.corr(df_vector, vector_col)\n"],"metadata":{},"outputs":[],"execution_count":42},{"cell_type":"code","source":["matrix.show()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+----------------------+\npearson(corr_features)|\n+----------------------+\n  1.0              ...|\n+----------------------+\n\n</div>"]}}],"execution_count":43},{"cell_type":"code","source":["sns.distplot(flights_df_sample_pandas['MONTH'])\ndisplay()"],"metadata":{},"outputs":[],"execution_count":44},{"cell_type":"code","source":["sns.distplot(flights_df_sample_pandas['DAY'])\ndisplay()"],"metadata":{},"outputs":[],"execution_count":45},{"cell_type":"code","source":["sns.distplot(flights_df_sample_pandas['DAY_OF_WEEK'])\ndisplay()"],"metadata":{},"outputs":[],"execution_count":46},{"cell_type":"code","source":["flights_df_sample_pandas['AIRLINE'].value_counts().plot(kind='bar')\ndisplay()"],"metadata":{},"outputs":[],"execution_count":47},{"cell_type":"code","source":["airline_count  = flights_df_sample_pandas['AIRLINE'].value_counts()\nairline_count = airline_count[:10,]\nplt.figure(figsize=(10,5))\nsns.barplot(airline_count.index, airline_count.values, alpha=0.8)\ndisplay()"],"metadata":{},"outputs":[],"execution_count":48},{"cell_type":"code","source":["oa_count  = flights_df_sample_pandas['ORIGIN_AIRPORT'].value_counts()\noa_count = oa_count[:10,]\nplt.figure(figsize=(10,5))\nsns.barplot(oa_count.index, oa_count.values, alpha=0.8)\ndisplay()"],"metadata":{},"outputs":[],"execution_count":49},{"cell_type":"code","source":["da_count  = flights_df_sample_pandas['DESTINATION_AIRPORT'].value_counts()\nda_count = da_count[:10,]\nplt.figure(figsize=(10,5))\nsns.barplot(da_count.index, da_count.values, alpha=0.8)\ndisplay()"],"metadata":{},"outputs":[],"execution_count":50},{"cell_type":"code","source":["sns.distplot(flights_df_sample_pandas['SCHEDULED_DEPARTURE'])\ndisplay()"],"metadata":{},"outputs":[],"execution_count":51},{"cell_type":"code","source":["sns.distplot(flights_df_sample_pandas['DEPARTURE_DELAY'])\ndisplay()"],"metadata":{},"outputs":[],"execution_count":52},{"cell_type":"code","source":["sns.distplot(flights_df_sample_pandas['DISTANCE'])\ndisplay()"],"metadata":{},"outputs":[],"execution_count":53},{"cell_type":"code","source":["sns.distplot(flights_df_sample_pandas['Distance_Bucket'])\ndisplay()"],"metadata":{},"outputs":[],"execution_count":54},{"cell_type":"code","source":["sns.distplot(flights_df_sample_pandas['SCHEDULED_ARRIVAL'])\ndisplay()"],"metadata":{},"outputs":[],"execution_count":55},{"cell_type":"code","source":["sns.distplot(flights_df_sample_pandas['CANCELLED'])\ndisplay()"],"metadata":{},"outputs":[],"execution_count":56},{"cell_type":"code","source":["sns.distplot(flights_df_sample_pandas['Flight_Delayed'])\ndisplay()"],"metadata":{},"outputs":[],"execution_count":57},{"cell_type":"code","source":["sns.barplot(x=\"MONTH\", y=\"DEPARTURE_DELAY\", data=flights_df_sample_pandas)\ndisplay()"],"metadata":{},"outputs":[],"execution_count":58},{"cell_type":"code","source":["sns.barplot(x=\"MONTH\", y=\"DEPARTURE_DELAY\", hue=\"Flight_Distance\", data=flights_df_sample_pandas)\ndisplay()"],"metadata":{},"outputs":[],"execution_count":59},{"cell_type":"code","source":["sns.barplot(x=\"DAY\", y=\"DEPARTURE_DELAY\", data=flights_df_sample_pandas)\ndisplay()"],"metadata":{},"outputs":[],"execution_count":60},{"cell_type":"code","source":["sns.barplot(x=\"DAY\", y=\"DEPARTURE_DELAY\", hue=\"Flight_Distance\", data=flights_df_sample_pandas)\ndisplay()"],"metadata":{},"outputs":[],"execution_count":61},{"cell_type":"code","source":["sns.barplot(x=\"DAY_OF_WEEK\", y=\"DEPARTURE_DELAY\", data=flights_df_sample_pandas)\ndisplay()"],"metadata":{},"outputs":[],"execution_count":62},{"cell_type":"code","source":["sns.barplot(x=\"DAY_OF_WEEK\", y=\"DEPARTURE_DELAY\", hue=\"Flight_Distance\", data=flights_df_sample_pandas)\ndisplay()"],"metadata":{},"outputs":[],"execution_count":63},{"cell_type":"code","source":["sns.barplot(x=\"AIRLINE\", y=\"DEPARTURE_DELAY\", data=flights_df_sample_pandas)\ndisplay()"],"metadata":{},"outputs":[],"execution_count":64},{"cell_type":"code","source":["sns.barplot(x=\"ORIGIN_AIRPORT\", y=\"DEPARTURE_DELAY\", data=flights_df_sample_pandas)\ndisplay()"],"metadata":{},"outputs":[],"execution_count":65},{"cell_type":"code","source":["sns.barplot(x=\"SCHEDULED_DEPARTURE\", y=\"DEPARTURE_DELAY\", data=flights_df_sample_pandas)\ndisplay()"],"metadata":{},"outputs":[],"execution_count":66},{"cell_type":"code","source":["sns.barplot(x=\"Distance_Bucket\", y=\"DEPARTURE_DELAY\", data=flights_df_sample_pandas)\ndisplay()"],"metadata":{},"outputs":[],"execution_count":67},{"cell_type":"code","source":["sns.barplot(x=\"AIRLINE\", y=\"DEPARTURE_DELAY\", hue=\"Flight_Distance\", data=flights_df_sample_pandas)\ndisplay()"],"metadata":{},"outputs":[],"execution_count":68},{"cell_type":"code","source":[""],"metadata":{},"outputs":[],"execution_count":69}],"metadata":{"name":"BDA_Project","notebookId":196724066013487},"nbformat":4,"nbformat_minor":0}
